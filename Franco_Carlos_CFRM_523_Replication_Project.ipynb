{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Franco Carlos | frnccc@uw.edu\n",
        "\n",
        "CFRM 523: Advanced Trading Systems\n",
        "\n",
        "Paper Replication Project:\n",
        "\n",
        "**A New Anomaly: The Cross-Sectional Profitability of Technical Analysis**\n",
        "\n",
        "by Yufeng Han, Ke Yang, and Guofu Zhou"
      ],
      "metadata": {
        "id": "hMBLmDaYf3bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary of the paper and literature review are submitted in full seperately. We begin with an abbreviated summary of the hypothesis in this notebook then replicate the trading strategy."
      ],
      "metadata": {
        "id": "4qScejoxg2nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of Strategy"
      ],
      "metadata": {
        "id": "ip-Epfg6hTCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trading strategy utilizes moving average timing of technical analysis, applied to portfolios sorted by volatility."
      ],
      "metadata": {
        "id": "Fro0kSpsi2Wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key analytical technique for the strategy that we will replicate is as follows:\n",
        "\n",
        "1.   **Obtain** the list of stocks (in the study, all stocks listed on the NYSE/Amex were used).\n",
        "2.   **Sort** each stock by their volatility, measured as the standard deviations of daily returns within a given year. **Divide** these stocks into ten equal deciles, or groups. This means that the first decile has the stocks with the lowest 10% volatility, and the tenth decile has the stocks with the highest 10% volatility. Each stock is equally weighted in a decile portfolio, and each year the portfolios are rebalanced according to the updated volatility.\n",
        "3.   For each decile portfolio, **compute** the 10-day moving average of the daily closing prices (or index levels) of the portfolio. Each day, if a portfolio's current price is above its 10-day MA, the **signal** is to buy or hold the portfolio. If below, the **signal** is to switch to the risk-free asset. **Apply the MA timing strategy** daily for each decile portfolio, moving between the portfolio and a risk-free asset based on the timing signals.\n",
        "4. **Track the returns** generated by the MA timing strategy for each decile portfolio. The paper uses the CAPM and Fama-French three-factor models to calculate risk-adjusted returns (alphas) of the MA timing strategy for comparison against the benchmark (buy-and-hold strategy).\n"
      ],
      "metadata": {
        "id": "CZx82rvlpHS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our hypothesis is that creating such a strategy that involves using the moving average on volatility-sorted decile portfolios will have a pattern of returns that differs from simply buying-and-holding these same portfolios."
      ],
      "metadata": {
        "id": "OHDMy4lteyC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to assess the probability that the strategy was overfit, the paper offered several robustness measures for the strategy. First, the paper considered alternative lag lengths for moving averages. They performed this strategy again for the MA(20) MA(50), MA(100) and MA(200) moving averages. Second, they performed this strategy by ordering the stocks based on their market cap instead of their volatility, and creating the decile portfolios based on this ordering."
      ],
      "metadata": {
        "id": "wzkPX7zue_gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We replicate their key analytical technqiues as well as their robustness measures for overfitting."
      ],
      "metadata": {
        "id": "LlNJr_I_gEye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "TWyO1EHyhK5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description and Source**"
      ],
      "metadata": {
        "id": "LakNMs2VhWmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper obtained all their data from the Center for Research in Security Prices (CRSP). They obtained the adjusted closing prices for all listed NYSE/Amex stocks from July 1, 1963 to December 31, 2009.\n",
        "\n",
        "However, their data was obtained under an institutional license granted to them, inaccessible to individual academic users. In that regard, the replication will need to address the following limitations in obtaining data:\n",
        "\n",
        "1.   Data needs to be readily available without a necessary institutional license from the respective source.\n",
        "2.   Data acquisition needs to be automated (i.e. ran through a library such as yfinance) in order to not have to be individually downloaded by hand.\n",
        "2.   Automated data acquisition must adhere to rate limits from the respective library.\n",
        "\n",
        "Thus, in this replication, the 10 volatility decile portfolios will be constructed using the stocks listed in the S&P 500, obtained using the yfinance library. Our frame of time will be from January 1 1980 to December 31 2022. This extends the analysis with more recent data, in a different asset index. Upon completing the strategy, we acknowledge the fundamental differences in the properties between NYSE/Amex and SP500, taking these into consideration when comparing these results to the paper's."
      ],
      "metadata": {
        "id": "KyB2qxaXri1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading, Cleaning, and Preparing Data**"
      ],
      "metadata": {
        "id": "zOtL0EY3hi7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to load all necessary packages."
      ],
      "metadata": {
        "id": "lHr41eqWv7Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas_datareader as pdr\n",
        "import datetime\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "EpeNRETmwJ_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next step imports the tickers of all stocks listed on the S&P500."
      ],
      "metadata": {
        "id": "ipQeRlSey4er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the file\n",
        "datapath = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/SP500.csv'\n",
        "data = pd.read_csv(datapath, delimiter=',')\n",
        "tickers = data['Symbol'].tolist()\n",
        "descriptions = data['Details'].tolist()\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(data.head())\n",
        "print(data.columns)\n",
        "# Display the first first 10 tickers and descriptions seperately\n",
        "print(tickers[:10])\n",
        "print(descriptions[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5arQk7lxlfz",
        "outputId": "d9d7e54b-3a7f-41dc-d262-350e93c067ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Symbol                Details\n",
            "0   MSFT  Microsoft Corporation\n",
            "1   AAPL              Apple Inc\n",
            "2   GOOG          Alphabet Inc.\n",
            "3  GOOGL          Alphabet Inc.\n",
            "4   NVDA     NVIDIA Corporation\n",
            "Index(['Symbol', 'Details'], dtype='object')\n",
            "['MSFT', 'AAPL', 'GOOG', 'GOOGL', 'NVDA', 'AMZN', 'META', 'BRK.B', 'LLY', 'AVGO']\n",
            "['Microsoft Corporation', 'Apple Inc', 'Alphabet Inc.', 'Alphabet Inc.', 'NVIDIA Corporation', 'Amazon.com, Inc.', 'Meta Platforms, Inc.', 'Berkshire Hathaway Inc.', 'Eli Lilly and Company', 'Broadcom Inc.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defined the start and end date, as well as the function, to fetch and download the adjusted closing price data."
      ],
      "metadata": {
        "id": "7yJBu6e_2YQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a start and end date for the historical data\n",
        "start_date = '1980-01-01'\n",
        "end_date = '2022-12-31'\n",
        "\n",
        "# Path to save the CSV file\n",
        "file_path = '/content/sp500_adj_close_data.csv'\n",
        "\n",
        "# Download historical data for each ticker\n",
        "def get_data(tickers, batch_size=10, sleep_time=2, file_path=file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        print(\"Data file exists. Loading data...\")\n",
        "        return pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
        "\n",
        "    print(\"Downloading new data...\")\n",
        "    all_data = pd.DataFrame()\n",
        "    for i in range(0, len(tickers), batch_size):\n",
        "        batch = tickers[i:i + batch_size]\n",
        "        data = yf.download(batch, start=start_date, end=end_date, progress=False)['Adj Close']\n",
        "        all_data = pd.concat([all_data, data], axis=1)\n",
        "        time.sleep(sleep_time)  # Pause for a few seconds between each batch\n",
        "    all_data.to_csv(file_path)\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "7uBjxkpJT-la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is not necessary to run. It downloaded and exported the .csv of closing prices.\n",
        "\n",
        "For computational efficiency, the data has already been saved and exported to an external GitHub repository."
      ],
      "metadata": {
        "id": "FU3qcbHBYjfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate daily returns and annualized volatility\n",
        "def calculate_volatility(data):\n",
        "    daily_returns = data.pct_change()\n",
        "    volatility = daily_returns.std() * np.sqrt(252)  # Annualizing the standard deviation\n",
        "    return volatility\n",
        "\n",
        "# Sort stocks into deciles based on volatility\n",
        "def sort_into_deciles(volatility):\n",
        "    deciles = pd.qcut(volatility, 10, labels=False, duplicates='drop')\n",
        "    return deciles\n",
        "\n",
        "# Function to process all steps\n",
        "def process_stock_data(tickers):\n",
        "    data = get_data(tickers)\n",
        "    if not data.empty:\n",
        "        volatility = calculate_volatility(data)\n",
        "        deciles = sort_into_deciles(volatility)\n",
        "        return deciles, data\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Execute the function\n",
        "deciles, stock_data = process_stock_data(tickers)\n",
        "\n",
        "# Check and print the decile information if available\n",
        "if deciles is not None and stock_data is not None:\n",
        "    for decile in range(10):\n",
        "        print(f\"Stocks in Decile {decile+1}:\")\n",
        "        print(stock_data.columns[deciles == decile])\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "id": "x_qXZ9OsvsRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code takes our adjusted closing prices, computes the volatilties for each asset, and sorts them into ten decile portfolios based on their volatilities. It begins by obtaining the closing prices from the linked GitHub .csv file."
      ],
      "metadata": {
        "id": "mf7OH0Bydfps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to save the CSV file\n",
        "file_path = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/sp500_adj_close.csv'\n",
        "\n",
        "# Load the data\n",
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
        "\n",
        "# Calculate daily returns and annualized volatility\n",
        "def calculate_volatility(data):\n",
        "    daily_returns = data.pct_change()\n",
        "    volatility = daily_returns.std() * np.sqrt(252)  # Annualizing the standard deviation\n",
        "    return volatility\n",
        "\n",
        "# Sort stocks into deciles based on volatility\n",
        "def sort_into_deciles(volatility):\n",
        "    deciles = pd.qcut(volatility, 10, labels=False, duplicates='drop')\n",
        "    return deciles\n",
        "\n",
        "# Function to process all steps\n",
        "def process_stock_data(file_path):\n",
        "    data = load_data(file_path)\n",
        "    if not data.empty:\n",
        "        volatility = calculate_volatility(data)\n",
        "        deciles = sort_into_deciles(volatility)\n",
        "        return deciles, data\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Execute the function\n",
        "deciles, stock_data = process_stock_data(file_path)\n",
        "\n",
        "# Check and print the decile information if available\n",
        "if deciles is not None and stock_data is not None:\n",
        "    for decile in range(10):\n",
        "        print(f\"Stocks in Decile {decile+1}:\")\n",
        "        print(stock_data.columns[deciles == decile])\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc-hs6VgTVDb",
        "outputId": "a56c02d4-f404-4a16-a0d7-72dbabae7e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks in Decile 1:\n",
            "Index(['JNJ', 'PG', 'XOM', 'KO', 'PEP', 'MCD', 'ABT', 'VZ', 'PM', 'NEE', 'T',\n",
            "       'UPS', 'MDLZ', 'DUK', 'SO', 'CL', 'BDX', 'ZTS', 'AJG', 'MMM', 'AEP',\n",
            "       'SRE', 'KMB', 'D', 'GIS', 'EXC', 'HSY', 'PEG', 'VRSK', 'ED', 'XEL',\n",
            "       'WEC', 'AWK', 'DTE', 'ETR', 'GPC', 'FE', 'ES', 'AEE', 'CBOE', 'HRL',\n",
            "       'K', 'PPL', 'ATO', 'AMCR', 'CPB', 'LNT', 'NI', 'SJM', 'EVRG'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 2:\n",
            "Index(['LLY', 'WMT', 'ABBV', 'CVX', 'MRK', 'IBM', 'PFE', 'RTX', 'UNP', 'ADP',\n",
            "       'BMY', 'MMC', 'GD', 'ITW', 'MO', 'NOC', 'AON', 'ECL', 'EMR', 'WELL',\n",
            "       'TRV', 'GWW', 'KDP', 'PSA', 'SYY', 'DG', 'PPG', 'XYL', 'FTV', 'EIX',\n",
            "       'WTW', 'CHD', 'BR', 'IFF', 'WRB', 'BAX', 'INVH', 'MKC', 'CINF', 'CLX',\n",
            "       'LDOS', 'L', 'ESS', 'CAG', 'MAA', 'UDR', 'ALLE', 'HII', 'FRT', 'PNW'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 3:\n",
            "Index(['V', 'ACN', 'LIN', 'GE', 'SPGI', 'ETN', 'HON', 'PGR', 'LMT', 'MDT',\n",
            "       'CVS', 'SHW', 'RSG', 'NSC', 'APD', 'HLT', 'KHC', 'O', 'AME', 'IQV',\n",
            "       'YUM', 'CHTR', 'OTIS', 'ACGL', 'VMC', 'CDW', 'EFX', 'WST', 'AVB', 'MTB',\n",
            "       'ZBH', 'DOV', 'ARE', 'BALL', 'ROL', 'CNP', 'OMC', 'CMS', 'AVY', 'IEX',\n",
            "       'EG', 'NTRS', 'WBA', 'NWS', 'NWSA', 'SNA', 'DOC', 'CPT', 'TFX'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 4:\n",
            "Index(['GOOG', 'GOOGL', 'COST', 'DIS', 'TMO', 'CAT', 'ELV', 'CB', 'DE', 'CI',\n",
            "       'TGT', 'MCK', 'PH', 'CSX', 'CTAS', 'PNC', 'TT', 'USB', 'PCAR', 'AZO',\n",
            "       'EL', 'TFC', 'ALL', 'KMI', 'TEL', 'FIS', 'KR', 'LHX', 'GEHC', 'ADM',\n",
            "       'DD', 'CAH', 'BRO', 'KEYS', 'MTD', 'EQR', 'WY', 'IRM', 'CPAY', 'PKG',\n",
            "       'DGX', 'SWK', 'PNR', 'IP', 'EMN', 'REG', 'BXP', 'AIZ', 'FMC', 'GL'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 5:\n",
            "Index(['MSFT', 'MA', 'WFC', 'AXP', 'DHR', 'COP', 'NKE', 'SYK', 'BA', 'BLK',\n",
            "       'FI', 'HCA', 'CME', 'FDX', 'MCO', 'PSX', 'TDG', 'ORLY', 'ROP', 'EW',\n",
            "       'COR', 'GM', 'STZ', 'OKE', 'SPG', 'BK', 'DLR', 'PAYX', 'CMI', 'MLM',\n",
            "       'GPN', 'ROK', 'EXR', 'VICI', 'EQT', 'FDS', 'BG', 'MAS', 'NDSN', 'TAP',\n",
            "       'AOS', 'KIM', 'RVTY', 'CRL', 'IPG', 'LW', 'CHRW', 'HSIC', 'BIO', 'CMA'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 6:\n",
            "Index(['AVGO', 'HD', 'JPM', 'CMCSA', 'GS', 'LOW', 'TJX', 'PLD', 'WM', 'SLB',\n",
            "       'APH', 'MAR', 'MSI', 'OXY', 'AFL', 'F', 'NUE', 'JCI', 'MSCI', 'CTVA',\n",
            "       'FAST', 'IR', 'LYB', 'GRMN', 'HPQ', 'WAB', 'TROW', 'HPE', 'STT', 'TSN',\n",
            "       'APTV', 'DRI', 'J', 'LUV', 'TXT', 'WAT', 'DPZ', 'EXPD', 'CFG', 'FOX',\n",
            "       'FOXA', 'POOL', 'ALB', 'LKQ', 'CTLT', 'UHS', 'BWA', 'HAS', 'RHI'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 7:\n",
            "Index(['META', 'UNH', 'BAC', 'CSCO', 'AMGN', 'INTC', 'TXN', 'BSX', 'SBUX',\n",
            "       'CMG', 'PANW', 'EOG', 'SNPS', 'ICE', 'MPC', 'PYPL', 'CPRT', 'MET',\n",
            "       'FTNT', 'HES', 'NEM', 'DOW', 'HUM', 'IDXX', 'NDAQ', 'PCG', 'GLW', 'RJF',\n",
            "       'RMD', 'FITB', 'CTRA', 'WBD', 'STE', 'TDY', 'RF', 'VTR', 'CE', 'JBHT',\n",
            "       'LH', 'SYF', 'MRO', 'NRG', 'KEY', 'ZBRA', 'HST', 'WRK', 'DVA', 'RL',\n",
            "       'TECH', 'MHK'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 8:\n",
            "Index(['AAPL', 'CRM', 'TMUS', 'NOW', 'BX', 'SCHW', 'C', 'ADI', 'ANET', 'PXD',\n",
            "       'NXPI', 'VLO', 'AIG', 'CARR', 'ADSK', 'ROST', 'AMP', 'LEN', 'A', 'CNC',\n",
            "       'PRU', 'CSGP', 'HAL', 'IT', 'BKR', 'DVN', 'DFS', 'ANSS', 'MPWR', 'DLTR',\n",
            "       'HWM', 'PHM', 'MOH', 'HBAN', 'PFG', 'CCL', 'STX', 'EXPE', 'EPAM',\n",
            "       'VTRS', 'APA', 'BBWI', 'MOS', 'QRVO', 'TPR', 'GNRC', 'MKTX', 'PARA',\n",
            "       'IVZ'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 9:\n",
            "Index(['ORCL', 'ADBE', 'INTU', 'QCOM', 'AMAT', 'MS', 'ISRG', 'AMT', 'GILD',\n",
            "       'KLAC', 'CDNS', 'FCX', 'CEG', 'COF', 'DHI', 'ODFL', 'WMB', 'MCHP',\n",
            "       'LULU', 'URI', 'CCI', 'SMCI', 'FANG', 'PWR', 'CTSH', 'EA', 'RCL',\n",
            "       'FICO', 'HIG', 'EBAY', 'TRGP', 'TTWO', 'STLD', 'LYV', 'ULTA', 'TYL',\n",
            "       'BBY', 'CF', 'TER', 'TRMB', 'MGM', 'GEN', 'JKHY', 'AES', 'PODD', 'KMX',\n",
            "       'PAYC', 'WYNN', 'DAY', 'MTCH'],\n",
            "      dtype='object')\n",
            "Stocks in Decile 10:\n",
            "Index(['AMZN', 'NVDA', 'TSLA', 'NFLX', 'AMD', 'UBER', 'BKNG', 'LRCX', 'MU',\n",
            "       'ABNB', 'VRTX', 'REGN', 'EQIX', 'MNST', 'DXCM', 'MRNA', 'LVS', 'BIIB',\n",
            "       'DAL', 'TSCO', 'CBRE', 'ON', 'NVR', 'ALGN', 'AXON', 'BLDR', 'WDC',\n",
            "       'HUBB', 'PTC', 'SBAC', 'DECK', 'NTAP', 'COO', 'FSLR', 'ILMN', 'VRSN',\n",
            "       'HOLX', 'UAL', 'AKAM', 'SWKS', 'ENPH', 'JBL', 'BEN', 'INCY', 'JNPR',\n",
            "       'FFIV', 'AAL', 'CZR', 'ETSY', 'NCLH'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Statistics**"
      ],
      "metadata": {
        "id": "MLxjvty9hr66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We report the same summary statistics as presented in the original research paper. This includes the average returns, standard deviation, skewness, and Sharpe ratios for each volatility decile portfolio, the MA(10) timing strategy portfolios, and each Moving Average Portfolio (MAP), expressed as the difference between the MA(10) and volatility decile portfolios."
      ],
      "metadata": {
        "id": "xd0VpbtJbyov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate statistics from data\n",
        "def calculate_statistics_test1(data):\n",
        "    daily_returns = data.pct_change()\n",
        "    mean_returns = daily_returns.mean().mean() * 252\n",
        "    std_dev = daily_returns.std().mean() * np.sqrt(252)\n",
        "    skewness = daily_returns.skew().mean()\n",
        "    sharpe_ratio = mean_returns / std_dev if std_dev != 0 else np.nan\n",
        "    return mean_returns, std_dev, skewness, sharpe_ratio\n",
        "\n",
        "# Assume 'deciles' and 'stock_data' are predefined variables\n",
        "results_test1 = {}\n",
        "\n",
        "if deciles is not None and stock_data is not None:\n",
        "    for decile in range(10):\n",
        "        decile_data = stock_data.loc[:, deciles == decile]\n",
        "        if not decile_data.empty:\n",
        "            results = calculate_statistics_test1(decile_data)\n",
        "            results_test1[f\"Decile {decile + 1}\"] = results\n",
        "        else:\n",
        "            results_test1[f\"Decile {decile + 1}\"] = None\n",
        "\n",
        "if deciles is not None and stock_data is not None:\n",
        "    for decile in range(10):\n",
        "        decile_data = stock_data.loc[:, deciles == decile]\n",
        "        if not decile_data.empty:\n",
        "            mean_returns, std_dev, skewness, sharpe_ratio = calculate_statistics_test1(decile_data)\n",
        "            print(f\"\\nSummary for Decile {decile + 1}:\")\n",
        "            print(f\"Average Returns: {mean_returns:.6f}\")\n",
        "            print(f\"Standard Deviation: {std_dev:.6f}\")\n",
        "            print(f\"Skewness: {skewness:.6f}\")\n",
        "            print(f\"Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "        else:\n",
        "            print(f\"\\nDecile {decile + 1} has no data.\")\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzt6SINKV-4J",
        "outputId": "0d71e4d4-f542-49f0-b2d7-17b7c2f34e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary for Decile 1:\n",
            "Average Returns: 0.142380\n",
            "Standard Deviation: 0.233098\n",
            "Skewness: 0.029865\n",
            "Sharpe Ratio: 0.610816\n",
            "\n",
            "Summary for Decile 2:\n",
            "Average Returns: 0.161559\n",
            "Standard Deviation: 0.270982\n",
            "Skewness: 0.124398\n",
            "Sharpe Ratio: 0.596197\n",
            "\n",
            "Summary for Decile 3:\n",
            "Average Returns: 0.167197\n",
            "Standard Deviation: 0.290885\n",
            "Skewness: 0.183948\n",
            "Sharpe Ratio: 0.574788\n",
            "\n",
            "Summary for Decile 4:\n",
            "Average Returns: 0.154358\n",
            "Standard Deviation: 0.313884\n",
            "Skewness: -0.037878\n",
            "Sharpe Ratio: 0.491765\n",
            "\n",
            "Summary for Decile 5:\n",
            "Average Returns: 0.199001\n",
            "Standard Deviation: 0.338661\n",
            "Skewness: 0.124165\n",
            "Sharpe Ratio: 0.587612\n",
            "\n",
            "Summary for Decile 6:\n",
            "Average Returns: 0.199437\n",
            "Standard Deviation: 0.366211\n",
            "Skewness: 0.017831\n",
            "Sharpe Ratio: 0.544594\n",
            "\n",
            "Summary for Decile 7:\n",
            "Average Returns: 0.199749\n",
            "Standard Deviation: 0.396372\n",
            "Skewness: 0.156311\n",
            "Sharpe Ratio: 0.503943\n",
            "\n",
            "Summary for Decile 8:\n",
            "Average Returns: 0.224954\n",
            "Standard Deviation: 0.437704\n",
            "Skewness: 0.264194\n",
            "Sharpe Ratio: 0.513942\n",
            "\n",
            "Summary for Decile 9:\n",
            "Average Returns: 0.282559\n",
            "Standard Deviation: 0.493210\n",
            "Skewness: 0.559215\n",
            "Sharpe Ratio: 0.572899\n",
            "\n",
            "Summary for Decile 10:\n",
            "Average Returns: 0.321647\n",
            "Standard Deviation: 0.700479\n",
            "Skewness: 5.768864\n",
            "Sharpe Ratio: 0.459181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the MA(10) portfolio and MAP returns are part of the analytical technique replication, and their summary statistics will follow."
      ],
      "metadata": {
        "id": "1lGdsN-Vd5p8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analytical Technique Replication"
      ],
      "metadata": {
        "id": "dw3BG4yBhdr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analytical Technique Replication**"
      ],
      "metadata": {
        "id": "ShrhX0KBiAki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_moving_average(data, window=10):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Apply the MA strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when out of the market\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)  # Convert numpy array to pandas Series\n",
        "    return strategy_returns.cumsum()  # Cumulative returns\n",
        "\n",
        "def implement_ma_strategy_for_deciles(stock_data, deciles, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for i in range(10):\n",
        "        decile_stocks = stock_data.columns[deciles == i]\n",
        "        decile_prices = stock_data[decile_stocks].mean(axis=1)  # Average price for each decile\n",
        "        ma_prices = calculate_moving_average(decile_prices)\n",
        "        strategy_results[f\"Decile {i+1}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "    return strategy_results\n",
        "\n",
        "if deciles is not None and stock_data is not None:\n",
        "    strategy_results = implement_ma_strategy_for_deciles(stock_data, deciles)\n",
        "    for key, value in strategy_results.items():\n",
        "        print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")  # Now 'value' is a pandas Series\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "id": "BVom_Zxt9ZI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03964e8c-2483-4096-950d-eed344cc6865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decile 1: Last cumulative return: 2.762424685029065\n",
            "Decile 2: Last cumulative return: 2.837077816665813\n",
            "Decile 3: Last cumulative return: 4.175456641337996\n",
            "Decile 4: Last cumulative return: 3.9969945720764\n",
            "Decile 5: Last cumulative return: 4.270129454834881\n",
            "Decile 6: Last cumulative return: 4.129935741437478\n",
            "Decile 7: Last cumulative return: 2.670110749025901\n",
            "Decile 8: Last cumulative return: 3.169593747712552\n",
            "Decile 9: Last cumulative return: 5.771735768127628\n",
            "Decile 10: Last cumulative return: 6.349655200848867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate statistics from daily returns\n",
        "def calculate_statistics_test2(daily_returns):\n",
        "    mean_returns = daily_returns.mean() * 252\n",
        "    std_dev = daily_returns.std() * np.sqrt(252)\n",
        "    skewness = daily_returns.skew()\n",
        "    sharpe_ratio = mean_returns / std_dev if std_dev != 0 else np.nan\n",
        "    return mean_returns, std_dev, skewness, sharpe_ratio\n",
        "\n",
        "def calculate_daily_returns_from_cumulative(cumulative_returns):\n",
        "    daily_returns = (cumulative_returns.pct_change().fillna(0) + 1).pow(1 / 252) - 1\n",
        "    return daily_returns\n",
        "\n",
        "# Assume 'strategy_results' contains the cumulative returns for each decile\n",
        "results_test2 = {}\n",
        "\n",
        "if strategy_results:\n",
        "    for key, cumulative_returns in strategy_results.items():\n",
        "        daily_returns = calculate_daily_returns_from_cumulative(cumulative_returns)\n",
        "        results = calculate_statistics_test2(daily_returns)\n",
        "        results_test2[key] = results"
      ],
      "metadata": {
        "id": "4t_4rpZEWBBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results of Hypothesis Tests, Comparison to Original Paper Results"
      ],
      "metadata": {
        "id": "AqJechlgiEhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_statistics(daily_returns):\n",
        "    \"\"\"Calculate aggregated mean return, standard deviation, skewness, and Sharpe Ratio for the provided data.\"\"\"\n",
        "    mean_returns = daily_returns.mean() * 252  # Annualize the mean returns\n",
        "    std_dev = daily_returns.std() * np.sqrt(252)  # Annualize the standard deviation\n",
        "    skewness = daily_returns.skew()  # Calculate skewness\n",
        "    sharpe_ratio = mean_returns / std_dev if std_dev != 0 else np.nan  # Calculate Sharpe Ratio\n",
        "    return mean_returns, std_dev, skewness, sharpe_ratio\n",
        "\n",
        "def calculate_daily_returns_from_cumulative(cumulative_returns):\n",
        "    \"\"\"Convert cumulative returns to daily returns.\"\"\"\n",
        "    daily_returns = (cumulative_returns.pct_change().fillna(0) + 1).pow(1 / 252) - 1  # Convert cumulative to daily and normalize to daily returns\n",
        "    return daily_returns"
      ],
      "metadata": {
        "id": "TN-slEl2ZWCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print results side by side with differences, sorted by decile number\n",
        "def print_results_side_by_side(results1, results2):\n",
        "    print(f\"{'Metric':>20} {'Test 1':>20} {'Test 2':>20} {'Difference':>20}\")\n",
        "\n",
        "    # Custom sorting function for keys that likely contain numeric values\n",
        "    sorted_keys = sorted(results1.keys(), key=lambda x: int(x.split()[1]))\n",
        "\n",
        "    for key in sorted_keys:\n",
        "        result1 = results1.get(key, ('n/a', 'n/a', 'n/a', 'n/a'))\n",
        "        result2 = results2.get(key, ('n/a', 'n/a', 'n/a', 'n/a'))\n",
        "        differences = []\n",
        "\n",
        "        # Calculate differences where applicable\n",
        "        for i in range(len(result1)):\n",
        "            if isinstance(result1[i], (float, int)) and isinstance(result2[i], (float, int)):\n",
        "                differences.append(result2[i] - result1[i])\n",
        "            else:\n",
        "                differences.append('n/a')\n",
        "\n",
        "        print(f\"\\n{key}:\")\n",
        "        print(f\"{'Average Returns:':>20} {result1[0]:>20.6f} {result2[0]:>20.6f} {differences[0]:>20.6f}\")\n",
        "        print(f\"{'Standard Deviation:':>20} {result1[1]:>20.6f} {result2[1]:>20.6f} {differences[1]:>20.6f}\")\n",
        "        print(f\"{'Skewness:':>20} {result1[2]:>20.6f} {result2[2]:>20.6f} {differences[2]:>20.6f}\")\n",
        "        print(f\"{'Sharpe Ratio:':>20} {result1[3]:>20.6f} {result2[3]:>20.6f} {differences[3]:>20.6f}\")\n",
        "\n",
        "# Call the function to display results\n",
        "print_results_side_by_side(results_test1, results_test2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNaCO-Kz4YU",
        "outputId": "1a156013-6190-4a77-b56b-310929178bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Metric               Test 1               Test 2           Difference\n",
            "\n",
            "Decile 1:\n",
            "    Average Returns:             0.142380             0.000948            -0.141432\n",
            " Standard Deviation:             0.233098             0.001910            -0.231188\n",
            "           Skewness:             0.029865            34.118681            34.088816\n",
            "       Sharpe Ratio:             0.610816             0.496211            -0.114605\n",
            "\n",
            "Decile 2:\n",
            "    Average Returns:             0.161559             0.000866            -0.160692\n",
            " Standard Deviation:             0.270982             0.003311            -0.267671\n",
            "           Skewness:             0.124398             5.197377             5.072979\n",
            "       Sharpe Ratio:             0.596197             0.261617            -0.334579\n",
            "\n",
            "Decile 3:\n",
            "    Average Returns:             0.167197             0.001423            -0.165774\n",
            " Standard Deviation:             0.290885             0.005016            -0.285870\n",
            "           Skewness:             0.183948            54.019590            53.835642\n",
            "       Sharpe Ratio:             0.574788             0.283717            -0.291071\n",
            "\n",
            "Decile 4:\n",
            "    Average Returns:             0.154358             0.001432            -0.152926\n",
            " Standard Deviation:             0.313884             0.005895            -0.307989\n",
            "           Skewness:            -0.037878            75.889337            75.927215\n",
            "       Sharpe Ratio:             0.491765             0.242899            -0.248866\n",
            "\n",
            "Decile 5:\n",
            "    Average Returns:             0.199001             0.000861            -0.198140\n",
            " Standard Deviation:             0.338661             0.004140            -0.334521\n",
            "           Skewness:             0.124165           -17.227208           -17.351373\n",
            "       Sharpe Ratio:             0.587612             0.208040            -0.379572\n",
            "\n",
            "Decile 6:\n",
            "    Average Returns:             0.199437             0.001410            -0.198026\n",
            " Standard Deviation:             0.366211             0.005937            -0.360275\n",
            "           Skewness:             0.017831            73.136725            73.118894\n",
            "       Sharpe Ratio:             0.544594             0.237522            -0.307072\n",
            "\n",
            "Decile 7:\n",
            "    Average Returns:             0.199749             0.001404            -0.198345\n",
            " Standard Deviation:             0.396372             0.007383            -0.388990\n",
            "           Skewness:             0.156311            29.797486            29.641175\n",
            "       Sharpe Ratio:             0.503943             0.190126            -0.313817\n",
            "\n",
            "Decile 8:\n",
            "    Average Returns:             0.224954             0.000751            -0.224203\n",
            " Standard Deviation:             0.437704             0.001994            -0.435710\n",
            "           Skewness:             0.264194            -2.223597            -2.487791\n",
            "       Sharpe Ratio:             0.513942             0.376616            -0.137326\n",
            "\n",
            "Decile 9:\n",
            "    Average Returns:             0.282559             0.002043            -0.280516\n",
            " Standard Deviation:             0.493210             0.007985            -0.485224\n",
            "           Skewness:             0.559215            27.060345            26.501130\n",
            "       Sharpe Ratio:             0.572899             0.255904            -0.316995\n",
            "\n",
            "Decile 10:\n",
            "    Average Returns:             0.321647             0.001546            -0.320100\n",
            " Standard Deviation:             0.700479             0.005751            -0.694727\n",
            "           Skewness:             5.768864            90.369763            84.600899\n",
            "       Sharpe Ratio:             0.459181             0.268807            -0.190374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZSZdnafWgCUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results Comparison**"
      ],
      "metadata": {
        "id": "mNkr-kP9iJZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimately, the results from replicating this strategy using the S&P500 as the universe of assets did not demonstrate abnormal or outperforming returns when compared to buying-and-holding the same asset portfolios. These results are contrary to the original results from the paper.\n",
        "\n",
        "Though this replication produced a results contrary to the results of the original hypothesis test, these results can be attributed to the differences in NYSE/Amex and the S&P500. We compare the application of the paperâ€™s techniques to its original method using the NYSE/Amex and the replicated techniques using the S&P500.\n",
        "\n",
        "The NYSE American lists a broad range of companies, including small to mid-cap stocks. The S&P500 is an index that includes the 500 largest companies listed on exchanges in the United States. This means that it is more heavily weighted towards large-cap industry leaders within their asset class.\n",
        "\n",
        "Small and mid-cap stocks have the chance to exhibit more volatile returns. This is because smaller companies have the potential to exhibit more potential growth. In comparison, the large-cap stocks listed on the S&P500 exhibit lower reactivity, thus leading to potentially more stable moving average portfolios and lower volatilities. Both of these technical analyses indicators were the core emphasis for this trading strategy. Additionally, the S&P500 is subsequently less diversified, as it focuses on the largest stocks in the US. Smaller stocks listed on NYSE/Amex can potentially exhibit macroeconomic reactions to the market.\n",
        "\n",
        "In conclusion, implementing the moving average timing strategy for volatility decile portfolios would have a less significant impact onto indices with assets of similar traits such as the S&P500. It is noted that the S&P500 was chosen for its computational efficiency given the scope of the project, and data availability, given that the source from the original paper was proprietary. NYSE/Amex volatility deciles were already obtained in their sorted portfolios from the Center for Research in Security Prices, but needed to be recomputed and sorted in replication. Finally, the Python library yfinance limits requests to 2,000 requests per hour per IP, limiting the amount of data that can be acquired from an individual retail perspective."
      ],
      "metadata": {
        "id": "nF7CAD8egB7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overfitness Assessment"
      ],
      "metadata": {
        "id": "HtEM7RdhiQKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the hypothesis test did not return the same results, the results are still tested for overfitness in the same manner as proposed by the original paper. There are two ways that the paper assesses overfitness in order to ensure a more robust and comprehensive hypothesis test."
      ],
      "metadata": {
        "id": "gnTdMnUOj-cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first method was to extend the same stest using alternative moving average lag lengths. These moving averages used the time frame of 20, 50, 100, and 200."
      ],
      "metadata": {
        "id": "XNktZMawlc99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MA(20) Portfolio**"
      ],
      "metadata": {
        "id": "UoqvZNfloBlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_moving_average20(data, window=20):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Apply the MA strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when out of the market\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)  # Convert numpy array to pandas Series\n",
        "    return strategy_returns.cumsum()  # Cumulative returns\n",
        "\n",
        "def implement_ma_strategy_for_deciles(stock_data, deciles, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for i in range(10):\n",
        "        decile_stocks = stock_data.columns[deciles == i]\n",
        "        decile_prices = stock_data[decile_stocks].mean(axis=1)  # Average price for each decile\n",
        "        ma_prices = calculate_moving_average20(decile_prices)\n",
        "        strategy_results[f\"Decile {i+1}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "    return strategy_results\n",
        "\n",
        "print(\"MA(20) Return Data:\")\n",
        "if deciles is not None and stock_data is not None:\n",
        "    strategy_results = implement_ma_strategy_for_deciles(stock_data, deciles)\n",
        "    for key, value in strategy_results.items():\n",
        "        print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")  # Now 'value' is a pandas Series\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "id": "M5xWJSfuli2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f3033e-fdea-4eb6-8803-cdf19dd0a519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MA(20) Return Data:\n",
            "Decile 1: Last cumulative return: 3.2513505444172006\n",
            "Decile 2: Last cumulative return: 3.2569565559988973\n",
            "Decile 3: Last cumulative return: 4.431888703850937\n",
            "Decile 4: Last cumulative return: 4.096161499400203\n",
            "Decile 5: Last cumulative return: 3.905553091793939\n",
            "Decile 6: Last cumulative return: 4.316364260435685\n",
            "Decile 7: Last cumulative return: 2.6169873204573855\n",
            "Decile 8: Last cumulative return: 3.8244068420207435\n",
            "Decile 9: Last cumulative return: 5.151978881562911\n",
            "Decile 10: Last cumulative return: 9.36108466059101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MA(50) Portfolio**"
      ],
      "metadata": {
        "id": "ZYai8lhaoHUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_moving_average50(data, window=50):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Apply the MA strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when out of the market\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)  # Convert numpy array to pandas Series\n",
        "    return strategy_returns.cumsum()  # Cumulative returns\n",
        "\n",
        "def implement_ma_strategy_for_deciles(stock_data, deciles, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for i in range(10):\n",
        "        decile_stocks = stock_data.columns[deciles == i]\n",
        "        decile_prices = stock_data[decile_stocks].mean(axis=1)  # Average price for each decile\n",
        "        ma_prices = calculate_moving_average50(decile_prices)\n",
        "        strategy_results[f\"Decile {i+1}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "    return strategy_results\n",
        "\n",
        "print(\"MA(50) Return Data:\")\n",
        "if deciles is not None and stock_data is not None:\n",
        "    strategy_results = implement_ma_strategy_for_deciles(stock_data, deciles)\n",
        "    for key, value in strategy_results.items():\n",
        "        print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")  # Now 'value' is a pandas Series\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2HzD4kQnkby",
        "outputId": "21df3438-8648-46b2-a998-a738a4549f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MA(50) Return Data:\n",
            "Decile 1: Last cumulative return: 3.1830539407735445\n",
            "Decile 2: Last cumulative return: 3.0067136814452278\n",
            "Decile 3: Last cumulative return: 4.369687863354437\n",
            "Decile 4: Last cumulative return: 4.083189979965746\n",
            "Decile 5: Last cumulative return: 4.275888519532658\n",
            "Decile 6: Last cumulative return: 4.734519340664028\n",
            "Decile 7: Last cumulative return: 3.625534471395323\n",
            "Decile 8: Last cumulative return: 3.3989876306092053\n",
            "Decile 9: Last cumulative return: 5.298297924770311\n",
            "Decile 10: Last cumulative return: 9.03834261706009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MA(100) Portfolio**"
      ],
      "metadata": {
        "id": "ZJJgA7JboIwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_moving_average100(data, window=100):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Apply the MA strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when out of the market\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)  # Convert numpy array to pandas Series\n",
        "    return strategy_returns.cumsum()  # Cumulative returns\n",
        "\n",
        "def implement_ma_strategy_for_deciles(stock_data, deciles, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for i in range(10):\n",
        "        decile_stocks = stock_data.columns[deciles == i]\n",
        "        decile_prices = stock_data[decile_stocks].mean(axis=1)  # Average price for each decile\n",
        "        ma_prices = calculate_moving_average100(decile_prices)\n",
        "        strategy_results[f\"Decile {i+1}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "    return strategy_results\n",
        "\n",
        "print(\"MA(100) Return Data:\")\n",
        "if deciles is not None and stock_data is not None:\n",
        "    strategy_results = implement_ma_strategy_for_deciles(stock_data, deciles)\n",
        "    for key, value in strategy_results.items():\n",
        "        print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")  # Now 'value' is a pandas Series\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b38zVMkgnuzT",
        "outputId": "3b567ef1-9d7f-4fac-9f35-480dc3d094cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MA(100) Return Data:\n",
            "Decile 1: Last cumulative return: 3.2932045914775134\n",
            "Decile 2: Last cumulative return: 3.597665967575709\n",
            "Decile 3: Last cumulative return: 4.165724498624777\n",
            "Decile 4: Last cumulative return: 4.633507106567501\n",
            "Decile 5: Last cumulative return: 4.824700502376047\n",
            "Decile 6: Last cumulative return: 4.695362238985849\n",
            "Decile 7: Last cumulative return: 3.895736174113976\n",
            "Decile 8: Last cumulative return: 3.080697254426471\n",
            "Decile 9: Last cumulative return: 5.619524140451109\n",
            "Decile 10: Last cumulative return: 7.752378240878296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MA(200) Portfolio**"
      ],
      "metadata": {
        "id": "SNsFaJWBoKCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_moving_average200(data, window=200):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Apply the MA strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when out of the market\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)  # Convert numpy array to pandas Series\n",
        "    return strategy_returns.cumsum()  # Cumulative returns\n",
        "\n",
        "def implement_ma_strategy_for_deciles(stock_data, deciles, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for i in range(10):\n",
        "        decile_stocks = stock_data.columns[deciles == i]\n",
        "        decile_prices = stock_data[decile_stocks].mean(axis=1)  # Average price for each decile\n",
        "        ma_prices = calculate_moving_average200(decile_prices)\n",
        "        strategy_results[f\"Decile {i+1}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "    return strategy_results\n",
        "\n",
        "print(\"MA(200) Return Data:\")\n",
        "if deciles is not None and stock_data is not None:\n",
        "    strategy_results = implement_ma_strategy_for_deciles(stock_data, deciles)\n",
        "    for key, value in strategy_results.items():\n",
        "        print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")  # Now 'value' is a pandas Series\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnvN4_WEn0_4",
        "outputId": "8fa42c1f-d752-48c7-eec9-728f9a98ceb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MA(200) Return Data:\n",
            "Decile 1: Last cumulative return: 3.818912230267257\n",
            "Decile 2: Last cumulative return: 3.9199394728428785\n",
            "Decile 3: Last cumulative return: 4.169707833346385\n",
            "Decile 4: Last cumulative return: 4.275336658973091\n",
            "Decile 5: Last cumulative return: 4.470790876525682\n",
            "Decile 6: Last cumulative return: 3.915161491096401\n",
            "Decile 7: Last cumulative return: 3.2638025573355973\n",
            "Decile 8: Last cumulative return: 3.8256868800916015\n",
            "Decile 9: Last cumulative return: 5.114735770237555\n",
            "Decile 10: Last cumulative return: 5.883137887832329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper originally reported that as the moving averages' time horizons increased, the reported returns from the study decreased. Replicating their alternative moving averages' lag lengths produced the same results."
      ],
      "metadata": {
        "id": "CzxQkGuHosbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second assessment for overfitness was using an alternative method to sort and partition the stocks into their decile portfolios. Alongside the volatility, decile portfolios were constructed by sorting the value-weighted market capitalization for all of their assessed stocks. The moving average portfolio strategy was then applied to it. We first partition the decile portfolios according to market cap rather than volatility:"
      ],
      "metadata": {
        "id": "0cYVYLny4ehV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load stock tickers from a CSV file\n",
        "def load_stock_tickers(datapath):\n",
        "    return pd.read_csv(datapath)\n",
        "\n",
        "# Function to fetch market cap data using yfinance\n",
        "def fetch_data(tickers):\n",
        "    market_caps = {}\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            market_cap = yf.Ticker(ticker).info.get('marketCap', None)\n",
        "            market_caps[ticker] = market_cap\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch data for {ticker}: {e}\")\n",
        "    return pd.DataFrame({'Ticker': tickers, 'MarketCap': [market_caps.get(ticker) for ticker in tickers]})\n",
        "\n",
        "# Function to sort stocks into market cap deciles\n",
        "def sort_into_market_cap_deciles(data):\n",
        "    data = data.dropna(subset=['MarketCap'])  # Remove rows where MarketCap is None\n",
        "    data.sort_values(by='MarketCap', ascending=False, inplace=True)\n",
        "    data['MarketCapDecile'] = pd.qcut(data['MarketCap'], 10, labels=range(1, 11))\n",
        "    return data\n",
        "\n",
        "# Main function to process stock data\n",
        "def process_stock_data(datapath):\n",
        "    tickers_df = load_stock_tickers(datapath)\n",
        "    tickers = tickers_df['Symbol'].tolist()\n",
        "    fetched_data = fetch_data(tickers)\n",
        "    if not fetched_data.empty:\n",
        "        sorted_data = sort_into_market_cap_deciles(fetched_data)\n",
        "        return sorted_data\n",
        "    return pd.DataFrame()  # Return an empty DataFrame if no data is fetched\n",
        "\n",
        "# Check and print the decile information if available\n",
        "if not stock_data.empty:\n",
        "    for decile in range(1, 11):\n",
        "        decile_tickers = stock_data[stock_data['MarketCapDecile'] == decile]['Ticker']\n",
        "        print(f\"Stocks in Market Cap Decile {decile}:\")\n",
        "        print(decile_tickers.tolist())\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNtLkEy0E0oe",
        "outputId": "b9840ba7-3502-4a2f-cc3f-7ce86a22cdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks in Market Cap Decile 1:\n",
            "['CRL', 'AES', 'LW', 'JNPR', 'IPG', 'INCY', 'DVA', 'PODD', 'EMN', 'REG', 'ALLE', 'WYNN', 'HII', 'PAYC', 'UHS', 'SOLV', 'KMX', 'FFIV', 'CPT', 'RL', 'QRVO', 'CTLT', 'MOS', 'BBWI', 'TECH', 'TFX', 'BXP', 'AAL', 'HSIC', 'TPR', 'DAY', 'AIZ', 'MTCH', 'PARA', 'PNW', 'FRT', 'CZR', 'CHRW', 'GNRC', 'BIO', 'NCLH', 'ETSY', 'HAS', 'MKTX', 'BWA', 'RHI', 'FMC', 'MHK', 'IVZ', 'CMA', 'GL']\n",
            "Stocks in Market Cap Decile 2:\n",
            "['CFG', 'MRO', 'SWKS', 'WBA', 'BG', 'AKAM', 'MAA', 'NRG', 'ENPH', 'TER', 'NDSN', 'CAG', 'CF', 'DGX', 'TRMB', 'JBL', 'FOXA', 'FOX', 'EPAM', 'SNA', 'POOL', 'NWS', 'NWSA', 'ZBRA', 'KEY', 'SWK', 'TAP', 'HST', 'BEN', 'MGM', 'CPB', 'VTRS', 'ALB', 'UDR', 'PNR', 'AMCR', 'GEN', 'LKQ', 'DOC', 'LNT', 'AOS', 'KIM', 'NI', 'SJM', 'RVTY', 'WRK', 'APA', 'IP', 'JKHY', 'EVRG']\n",
            "Stocks in Market Cap Decile 3:\n",
            "['STE', 'AEE', 'K', 'HBAN', 'HRL', 'ILMN', 'TDY', 'PFG', 'APTV', 'CBOE', 'CINF', 'FSLR', 'CCL', 'VRSN', 'DRI', 'OMC', 'CNP', 'J', 'TXT', 'CLX', 'EXPE', 'CMS', 'COO', 'HOLX', 'STX', 'ATO', 'LUV', 'WAT', 'UAL', 'RF', 'TYL', 'VTR', 'IEX', 'CE', 'JBHT', 'SYF', 'NTRS', 'LH', 'AVY', 'LDOS', 'L', 'EQT', 'FDS', 'DPZ', 'EG', 'EXPD', 'BBY', 'PKG', 'ESS', 'MAS']\n",
            "Stocks in Market Cap Decile 4:\n",
            "['CAH', 'FITB', 'NVR', 'TROW', 'ZBH', 'MTB', 'TTWO', 'EQR', 'BRO', 'BF-B', 'DOV', 'AWK', 'WY', 'ETR', 'BR', 'DTE', 'PHM', 'GPC', 'ALGN', 'VLTO', 'STT', 'IRM', 'AXON', 'FE', 'WDC', 'HPE', 'BLDR', 'STLD', 'IFF', 'TSN', 'CPAY', 'WRB', 'PTC', 'SBAC', 'MOH', 'ES', 'CTRA', 'HUBB', 'DECK', 'WBD', 'ARE', 'INVH', 'BALL', 'BAX', 'ROL', 'LYV', 'NTAP', 'PPL', 'ULTA', 'MKC']\n",
            "Stocks in Market Cap Decile 5:\n",
            "['EA', 'RCL', 'CTSH', 'VMC', 'PEG', 'DVN', 'LYB', 'BKR', 'ED', 'CDW', 'VRSK', 'DFS', 'GPN', 'DAL', 'DG', 'ADM', 'ROK', 'XYL', 'DD', 'PPG', 'XEL', 'HIG', 'VICI', 'MPWR', 'EXR', 'FICO', 'ANSS', 'FTV', 'BIIB', 'WST', 'TSCO', 'EIX', 'WTW', 'HPQ', 'EFX', 'GRMN', 'GLW', 'AVB', 'RMD', 'DLTR', 'CBRE', 'EBAY', 'RJF', 'ON', 'WEC', 'CHD', 'WAB', 'HWM', 'MTD', 'TRGP', 'KEYS']\n",
            "Stocks in Market Cap Decile 6:\n",
            "['JCI', 'PAYX', 'KMB', 'DLR', 'NEM', 'KDP', 'BK', 'D', 'URI', 'AMP', 'IQV', 'SMCI', 'LEN', 'KMI', 'CCI', 'AME', 'FIS', 'KR', 'MSCI', 'CNC', 'DOW', 'GIS', 'PRU', 'MRNA', 'IDXX', 'CMI', 'LHX', 'A', 'HUM', 'YUM', 'OTIS', 'FAST', 'CTVA', 'SYY', 'GEHC', 'CHTR', 'HSY', 'EXC', 'KVUE', 'GEV', 'FANG', 'MLM', 'PWR', 'IR', 'NDAQ', 'ACGL', 'CSGP', 'LVS', 'IT', 'HAL']\n",
            "Stocks in Market Cap Decile 7:\n",
            "['PCAR', 'CEG', 'ROP', 'MSI', 'MNST', 'COF', 'NXPI', 'NSC', 'VLO', 'WELL', 'SPG', 'EL', 'EW', 'APD', 'MET', 'AJG', 'MMM', 'CPRT', 'AZO', 'F', 'TFC', 'DXCM', 'AIG', 'GM', 'TRV', 'HLT', 'FTNT', 'CARR', 'HES', 'AFL', 'STZ', 'DHI', 'COR', 'WMB', 'OKE', 'ADSK', 'KHC', 'GWW', 'ALL', 'PSA', 'ODFL', 'NUE', 'O', 'LULU', 'MCHP', 'SRE', 'ROST', 'AEP', 'TEL', 'PCG']\n",
            "Stocks in Market Cap Decile 8:\n",
            "['CVS', 'FI', 'KLAC', 'GILD', 'WM', 'HCA', 'AMT', 'GD', 'SO', 'CMG', 'SNPS', 'SHW', 'CDNS', 'CME', 'TGT', 'EOG', 'ANET', 'DUK', 'ICE', 'ITW', 'MO', 'CL', 'EQIX', 'MPC', 'SLB', 'FCX', 'NOC', 'PH', 'MCK', 'MCO', 'MAR', 'CSX', 'BDX', 'CTAS', 'APH', 'TDG', 'PSX', 'PYPL', 'ZTS', 'FDX', 'TT', 'ORLY', 'USB', 'PXD', 'ECL', 'EMR', 'PNC', 'AON', 'RSG', 'OXY']\n",
            "Stocks in Market Cap Decile 9:\n",
            "['COP', 'MS', 'TXN', 'PFE', 'BX', 'NOW', 'INTC', 'PM', 'AMGN', 'UBER', 'UNP', 'NKE', 'SCHW', 'GS', 'RTX', 'NEE', 'SPGI', 'LOW', 'ISRG', 'HON', 'PGR', 'SYK', 'UPS', 'ELV', 'ETN', 'MU', 'BKNG', 'T', 'C', 'LRCX', 'BLK', 'DE', 'LMT', 'MDT', 'TJX', 'BA', 'VRTX', 'CB', 'ADP', 'CI', 'BSX', 'SBUX', 'BMY', 'ABNB', 'MMC', 'REGN', 'PLD', 'MDLZ', 'ADI', 'PANW']\n",
            "Stocks in Market Cap Decile 10:\n",
            "['MSFT', 'AAPL', 'NVDA', 'GOOG', 'GOOGL', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM', 'WMT', 'XOM', 'UNH', 'TSLA', 'MA', 'PG', 'JNJ', 'HD', 'MRK', 'COST', 'ORCL', 'CVX', 'ABBV', 'BAC', 'CRM', 'KO', 'PEP', 'AMD', 'NFLX', 'LIN', 'WFC', 'TMO', 'ADBE', 'DIS', 'ACN', 'MCD', 'CSCO', 'TMUS', 'ABT', 'QCOM', 'CAT', 'DHR', 'INTU', 'AXP', 'IBM', 'GE', 'VZ', 'CMCSA', 'AMAT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load stock tickers from a CSV file\n",
        "def load_stock_tickers(datapath):\n",
        "    return pd.read_csv(datapath)\n",
        "\n",
        "# Function to fetch market cap data using yfinance\n",
        "def fetch_data(tickers):\n",
        "    market_caps = {}\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            market_cap = yf.Ticker(ticker).info.get('marketCap', None)\n",
        "            market_caps[ticker] = market_cap\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch data for {ticker}: {e}\")\n",
        "    return pd.DataFrame({'Ticker': tickers, 'MarketCap': [market_caps.get(ticker) for ticker in tickers]})\n",
        "\n",
        "# Function to sort stocks into market cap deciles\n",
        "def sort_into_market_cap_deciles(data):\n",
        "    data = data.dropna(subset=['MarketCap'])  # Remove rows where MarketCap is None\n",
        "    data.sort_values(by='MarketCap', ascending=False, inplace=True)\n",
        "    data['MarketCapDecile'] = pd.qcut(data['MarketCap'], 10, labels=range(1, 11))\n",
        "    return data\n",
        "\n",
        "# Function to calculate statistics from data\n",
        "def calculate_statistics(data):\n",
        "    daily_returns = data.pct_change()\n",
        "    portfolio_returns = daily_returns.mean(axis=1)\n",
        "    mean_returns = portfolio_returns.mean() * 252\n",
        "    std_dev = portfolio_returns.std() * np.sqrt(252)\n",
        "    skewness = portfolio_returns.skew()\n",
        "    sharpe_ratio = mean_returns / std_dev if std_dev != 0 else np.nan\n",
        "    return mean_returns, std_dev, skewness, sharpe_ratio\n",
        "\n",
        "# Main function to process stock data\n",
        "def process_stock_data(datapath, historical_data_path):\n",
        "    tickers_df = load_stock_tickers(datapath)\n",
        "    tickers = tickers_df['Symbol'].tolist()\n",
        "    fetched_data = fetch_data(tickers)\n",
        "    historical_data = pd.read_csv(historical_data_path, index_col=0)\n",
        "\n",
        "    if not fetched_data.empty:\n",
        "        sorted_data = sort_into_market_cap_deciles(fetched_data)\n",
        "        decile_stats = {}\n",
        "        for decile in range(1, 11):\n",
        "            decile_tickers = sorted_data[sorted_data['MarketCapDecile'] == decile]['Ticker'].tolist()\n",
        "            decile_data = historical_data[decile_tickers]\n",
        "            if not decile_data.empty:\n",
        "                stats = calculate_statistics(decile_data)\n",
        "                decile_stats[f\"Decile {decile}\"] = stats\n",
        "            else:\n",
        "                decile_stats[f\"Decile {decile}\"] = \"No data available.\"\n",
        "        return decile_stats\n",
        "    return {}\n",
        "\n",
        "datapath = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/SP500.csv'\n",
        "historical_data_path = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/sp500_adj_close.csv'\n",
        "decile_statistics = process_stock_data(datapath, historical_data_path)\n",
        "\n",
        "for decile, stats in decile_statistics.items():\n",
        "    if isinstance(stats, tuple):\n",
        "        mean_returns, std_dev, skewness, sharpe_ratio = stats\n",
        "        print(f\"\\nSummary for Marketp Cap {decile}:\")\n",
        "        print(f\"Average Returns: {mean_returns:.6f}\")\n",
        "        print(f\"Standard Deviation: {std_dev:.6f}\")\n",
        "        print(f\"Skewness: {skewness:.6f}\")\n",
        "        print(f\"Sharpe Ratio: {sharpe_ratio:.6f}\")\n",
        "    else:\n",
        "        print(f\"\\nSummary for Decile {decile}: {stats}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYUNE_ZdK2ZJ",
        "outputId": "82acd1bf-542d-4b69-d903-8457de424fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary for Marketp Cap Decile 1:\n",
            "Average Returns: 0.203169\n",
            "Standard Deviation: 0.200430\n",
            "Skewness: -0.231571\n",
            "Sharpe Ratio: 1.013665\n",
            "\n",
            "Summary for Marketp Cap Decile 2:\n",
            "Average Returns: 0.188167\n",
            "Standard Deviation: 0.184553\n",
            "Skewness: -0.347091\n",
            "Sharpe Ratio: 1.019582\n",
            "\n",
            "Summary for Marketp Cap Decile 3:\n",
            "Average Returns: 0.191625\n",
            "Standard Deviation: 0.181705\n",
            "Skewness: -0.419724\n",
            "Sharpe Ratio: 1.054598\n",
            "\n",
            "Summary for Marketp Cap Decile 4:\n",
            "Average Returns: 0.227776\n",
            "Standard Deviation: 0.237059\n",
            "Skewness: 26.879787\n",
            "Sharpe Ratio: 0.960840\n",
            "\n",
            "Summary for Marketp Cap Decile 5:\n",
            "Average Returns: 0.204059\n",
            "Standard Deviation: 0.183402\n",
            "Skewness: -0.400493\n",
            "Sharpe Ratio: 1.112635\n",
            "\n",
            "Summary for Marketp Cap Decile 6:\n",
            "Average Returns: 0.200680\n",
            "Standard Deviation: 0.181565\n",
            "Skewness: -0.510929\n",
            "Sharpe Ratio: 1.105281\n",
            "\n",
            "Summary for Marketp Cap Decile 7:\n",
            "Average Returns: 0.197629\n",
            "Standard Deviation: 0.183237\n",
            "Skewness: -0.456821\n",
            "Sharpe Ratio: 1.078539\n",
            "\n",
            "Summary for Marketp Cap Decile 8:\n",
            "Average Returns: 0.191918\n",
            "Standard Deviation: 0.176730\n",
            "Skewness: -0.537673\n",
            "Sharpe Ratio: 1.085942\n",
            "\n",
            "Summary for Marketp Cap Decile 9:\n",
            "Average Returns: 0.201483\n",
            "Standard Deviation: 0.195631\n",
            "Skewness: -0.353598\n",
            "Sharpe Ratio: 1.029912\n",
            "\n",
            "Summary for Marketp Cap Decile 10:\n",
            "Average Returns: 0.224435\n",
            "Standard Deviation: 0.197378\n",
            "Skewness: -0.398653\n",
            "Sharpe Ratio: 1.137085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then perform the Moving Average Portfolio for MA(10), MA(20), MA(50), MA(100), and MA(200) to these portfolios"
      ],
      "metadata": {
        "id": "hsc_1gPs4sp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the moving average for the given data over a specified window\n",
        "def calculate_moving_average(data, window=10):\n",
        "    return data.rolling(window=window).mean()\n",
        "\n",
        "# Function to apply the Moving Average (MA) trading strategy\n",
        "def apply_ma_strategy(prices, ma_prices, risk_free_rate):\n",
        "    signals = prices.shift(1) > ma_prices.shift(1)  # True if prices are above the MA of the previous day\n",
        "    daily_returns = prices.pct_change()\n",
        "    strategy_returns = np.where(signals, daily_returns, risk_free_rate)  # Apply risk-free returns when the signal is not true\n",
        "    strategy_returns = pd.Series(strategy_returns, index=prices.index)\n",
        "    return strategy_returns.cumsum()  # Calculate cumulative returns\n",
        "\n",
        "# Function to implement the moving average strategy for each market cap decile\n",
        "def implement_ma_strategy_for_deciles(sorted_data, historical_data, risk_free_rate=0.0001 / 252):\n",
        "    strategy_results = {}\n",
        "    for decile in range(1, 11):\n",
        "        decile_tickers = sorted_data[sorted_data['MarketCapDecile'] == decile]['Ticker'].tolist()\n",
        "        if decile_tickers:\n",
        "            decile_prices = historical_data[decile_tickers].mean(axis=1)  # Calculate average prices for the decile\n",
        "            ma_prices = calculate_moving_average(decile_prices)\n",
        "            strategy_results[f\"Decile {decile}\"] = apply_ma_strategy(decile_prices, ma_prices, risk_free_rate)\n",
        "        else:\n",
        "            strategy_results[f\"Decile {decile}\"] = \"No data available\"\n",
        "    return strategy_results\n",
        "\n",
        "# Load and process the stock data\n",
        "datapath = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/SP500.csv'\n",
        "historical_data_path = 'https://raw.githubusercontent.com/franco-rey/cfrm-523-replication-project/main/sp500_adj_close.csv'\n",
        "tickers_df = load_stock_tickers(datapath)\n",
        "tickers = tickers_df['Symbol'].tolist()\n",
        "fetched_data = fetch_data(tickers)\n",
        "historical_data = pd.read_csv(historical_data_path, index_col=0)\n",
        "\n",
        "# Sort the data into market cap deciles and apply the moving average strategy\n",
        "if not fetched_data.empty:\n",
        "    sorted_data = sort_into_market_cap_deciles(fetched_data)\n",
        "    strategy_results = implement_ma_strategy_for_deciles(sorted_data, historical_data)\n",
        "    for key, value in strategy_results.items():\n",
        "        if isinstance(value, pd.Series):\n",
        "            print(f\"{key}: Last cumulative return: {value.iloc[-1]}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "else:\n",
        "    print(\"No data available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEAKRcU7SKAe",
        "outputId": "07408569-9c8e-440f-840d-2e7550ba6704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decile 1: Last cumulative return: 4.543385627855605\n",
            "Decile 2: Last cumulative return: 3.940010001932284\n",
            "Decile 3: Last cumulative return: 3.458903704702103\n",
            "Decile 4: Last cumulative return: 3.4257126370512\n",
            "Decile 5: Last cumulative return: 3.900175625099975\n",
            "Decile 6: Last cumulative return: 4.006173735871204\n",
            "Decile 7: Last cumulative return: 2.74501971015376\n",
            "Decile 8: Last cumulative return: 5.034718115316057\n",
            "Decile 9: Last cumulative return: 5.1451773125227245\n",
            "Decile 10: Last cumulative return: 2.6108429573064087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert cumulative returns to daily returns\n",
        "def calculate_daily_returns_from_cumulative(cumulative_returns):\n",
        "    # The first value will be NaN because pct_change has nothing to compare it to\n",
        "    daily_returns = cumulative_returns.pct_change().fillna(0)\n",
        "    return daily_returns\n",
        "\n",
        "\n",
        "# Function to calculate statistics\n",
        "def calculate_statistics_from_returns(daily_returns):\n",
        "    mean_returns = daily_returns.mean() * 252\n",
        "    std_dev = daily_returns.std() * np.sqrt(252)\n",
        "    skewness = daily_returns.skew()\n",
        "    sharpe_ratio = mean_returns / std_dev if std_dev != 0 else np.nan\n",
        "    return mean_returns, std_dev, skewness, sharpe_ratio\n",
        "\n",
        "# Prepare for the comparison\n",
        "comparison_results = {}\n",
        "\n",
        "# Make sure to calculate statistics for both the original and strategy returns\n",
        "for decile in range(1, 11):\n",
        "    decile_key = f\"Decile {decile}\"\n",
        "    original_stats = decile_statistics[decile_key] if decile_key in decile_statistics else (np.nan, np.nan, np.nan, np.nan)\n",
        "    strategy_series = strategy_results[decile_key] if decile_key in strategy_results and isinstance(strategy_results[decile_key], pd.Series) else pd.Series(np.nan, index=historical_data.index)\n",
        "\n",
        "    # Convert cumulative strategy returns to daily returns\n",
        "    strategy_daily_returns = calculate_daily_returns_from_cumulative(strategy_series)\n",
        "    strategy_stats = calculate_statistics_from_returns(strategy_daily_returns)\n",
        "\n",
        "    # Calculate the differences\n",
        "    differences = tuple(s - o for o, s in zip(original_stats, strategy_stats))\n",
        "\n",
        "    # Store results\n",
        "    comparison_results[decile_key] = (original_stats, strategy_stats, differences)\n",
        "\n",
        "# Printing function\n",
        "def print_comparative_results(comparison_results):\n",
        "    metrics = ['Average Returns', 'Standard Deviation', 'Skewness', 'Sharpe Ratio']\n",
        "    print(f\"{'Decile':<10}{'Metric':<20}{'Test 1':<20}{'Test 2':<20}{'Difference':<20}\")\n",
        "\n",
        "    for decile in range(1, 11):\n",
        "        decile_key = f\"Decile {decile}\"\n",
        "        print(f\"{decile_key:<10}\")\n",
        "        for i, metric in enumerate(metrics):\n",
        "            original, strategy, differences = comparison_results[decile_key]\n",
        "            print(f\"{'':<10}{metric:<20}{original[i]:<20.6f}{strategy[i]:<20.6f}{differences[i]:<20.6f}\")\n",
        "        print('-' * 80)\n",
        "\n",
        "# Run the printing function\n",
        "print_comparative_results(comparison_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wH9dElRTrTI",
        "outputId": "e57ed2c1-cd37-4abd-dde3-125d5db996b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decile    Metric              Test 1              Test 2              Difference          \n",
            "Decile 1  \n",
            "          Average Returns     0.203169            -6.541615           -6.744784           \n",
            "          Standard Deviation  0.200430            49.086749           48.886319           \n",
            "          Skewness            -0.231571           -95.688716          -95.457145          \n",
            "          Sharpe Ratio        1.013665            -0.133266           -1.146932           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 2  \n",
            "          Average Returns     0.188167            31.931501           31.743334           \n",
            "          Standard Deviation  0.184553            203.988456          203.803903          \n",
            "          Skewness            -0.347091           104.061960          104.409050          \n",
            "          Sharpe Ratio        1.019582            0.156536            -0.863046           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 3  \n",
            "          Average Returns     0.191625            -53.775943          -53.967569          \n",
            "          Standard Deviation  0.181705            353.841102          353.659397          \n",
            "          Skewness            -0.419724           -104.128282         -103.708559         \n",
            "          Sharpe Ratio        1.054598            -0.151978           -1.206576           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 4  \n",
            "          Average Returns     0.227776            84.840125           84.612349           \n",
            "          Standard Deviation  0.237059            558.162086          557.925027          \n",
            "          Skewness            26.879787           104.126173          77.246386           \n",
            "          Sharpe Ratio        0.960840            0.151999            -0.808841           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 5  \n",
            "          Average Returns     0.204059            -7.791002           -7.995061           \n",
            "          Standard Deviation  0.183402            53.018183           52.834781           \n",
            "          Skewness            -0.400493           -104.076484         -103.675991         \n",
            "          Sharpe Ratio        1.112635            -0.146950           -1.259585           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 6  \n",
            "          Average Returns     0.200680            -41.207052          -41.407732          \n",
            "          Standard Deviation  0.181565            282.808546          282.626981          \n",
            "          Skewness            -0.510929           -103.897029         -103.386100         \n",
            "          Sharpe Ratio        1.105281            -0.145707           -1.250988           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 7  \n",
            "          Average Returns     0.197629            -21.263211          -21.460840          \n",
            "          Standard Deviation  0.183237            152.056011          151.872773          \n",
            "          Skewness            -0.456821           -102.398504         -101.941683         \n",
            "          Sharpe Ratio        1.078539            -0.139838           -1.218377           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 8  \n",
            "          Average Returns     0.191918            -30.342204          -30.534123          \n",
            "          Standard Deviation  0.176730            202.680217          202.503487          \n",
            "          Skewness            -0.537673           -104.121272         -103.583598         \n",
            "          Sharpe Ratio        1.085942            -0.149705           -1.235647           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 9  \n",
            "          Average Returns     0.201483            -5.151102           -5.352585           \n",
            "          Standard Deviation  0.195631            31.594221           31.398590           \n",
            "          Skewness            -0.353598           -102.415651         -102.062053         \n",
            "          Sharpe Ratio        1.029912            -0.163039           -1.192951           \n",
            "--------------------------------------------------------------------------------\n",
            "Decile 10 \n",
            "          Average Returns     0.224435            7.668406            7.443970            \n",
            "          Standard Deviation  0.197378            49.117945           48.920567           \n",
            "          Skewness            -0.398653           69.874228           70.272881           \n",
            "          Sharpe Ratio        1.137085            0.156122            -0.980963           \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inconsistency of these resutls can be attributed to the differences in characteristics between the S&P500 and NYSE/Amex that were mentioned previously."
      ],
      "metadata": {
        "id": "o5Jb4mmSghyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Opportunities for Future Research"
      ],
      "metadata": {
        "id": "rsv3SPjZir6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   The first natural opportunity for further research would be to extend this strategy into subsequent markets and asset classes, investigating the cross-sectional profitability of this strategy when expsoed to different conditions.\n",
        "2.   In the study, the Capital Asset Pricing and Fama-French Three Factor models were the models used to model the returns of the moving average portfolios. The study can be reaffirmed to be made more robust with the assessment of returns across additional pricing and return models. This can include Stephen Ross' Arbitrage Pricing Theory, the later developed Fama-French five factor model (adding profitability and investment), or conditional asset pricing models. The hypothesis and method would remain the same, but would be augmented by verifying the returns under further models.\n",
        "3.   Using the moving average, and more generally speaking technical analysis, is inherently a trend-following strategy. Because of this trend-following strategy, investment issues that have been investigated around the momentum strategy can also be investigated with the moving average strategy.\n",
        "4.   Hypotheses for future research tests would remain the same. The fundamental philosophy of this strategy is to partition a market segment or asset class into several portfolios, and apply a chosen trading strategy both using technical analysis. Further research therefore lies in different asset classes or market segments, different models of returns, or different technical analysis methods."
      ],
      "metadata": {
        "id": "Ji0lmGFyVidx"
      }
    }
  ]
}